import { generateText, streamText } from 'ai';
import { createGroq, createGoogle } from '@/lib/ai/providers';

export const orchestrator = {
    /**
     * Hybrid workflow: 
     * 1. Groq (Llama-3) plans the response and selects relevant files/context.
     * 2. Gemini (Flash) executes the plan and streams the response.
     */
    async streamHybridResponse(messages: any[], context: string, onFinish?: (text: string) => Promise<void>, apiKeys?: { groq?: string, google?: string }) {

        // Squash messages for Groq (Llama 3) to avoid any structural/typing issues with the API
        // We convert the history into a single "Context" block in the user message.
        const conversationHistory = messages
            .filter(m => m.role === 'user' || m.role === 'assistant')
            .map(m => {
                let content = m.content;
                if (Array.isArray(content)) {
                    content = content
                        .filter((c: any) => c.type === 'text')
                        .map((c: any) => c.text)
                        .join('');
                }
                return `${m.role.toUpperCase()}: ${content}`;
            })
            .join('\n\n');
        // ye groq or Librarian ka prompt hh
        const { text: plan } = await generateText({
            model: createGroq(apiKeys?.groq)('llama-3.1-8b-instant'),
            system: `You are an expert software architect acting as a "Librarian". 
            Your goal is to analyze the user's latest query and the repo structure to create a concise "Research Plan".
            
            Repo Structure/Context:
            ${context}
            
            Output ONLY the plan. Be specific about what files or concepts the "Writer" agent should look for.`,
            messages: [
                {
                    role: 'user',
                    content: `Here is the conversation history so far:\n\n${conversationHistory}\n\nPlease generate the research plan for the latest user query.`
                }
            ],
        });

        // ye gemini or Architect ka prompt hh 
        const result = await streamText({
            model: createGoogle(apiKeys?.google)('gemini-2.5-flash'),
            system: `You are an expert developer. 
            CONTEXT:
            ${context}
            
            RESEARCH PLAN (generated by Librarian):
            ${plan}
            
            Instructions:
            - Follow the plan to answer the user's question.
            - Use the provided context.
            - Format nicely with Markdown.
            - BE EXTREMELY CONCISE. Focus primarily on Tech Stack and Architecture unless asked otherwise.
            - Avoid generic introductions or conclusions. Go straight to the point.
            - If explaining architecture or flow, YOU CAN GENERATE A DIAGRAM. output a \`mermaid\` code block.
            - CRITICAL: When creating mermaid diagrams, ALWAYS put node labels in quotes. Example: id["Label (with text)"] instead of id[Label (with text)]. This prevents syntax errors.`,
            messages,
            onFinish: async ({ text }) => {
                if (onFinish) await onFinish(text);
            }
        });

        return result;
    }
};